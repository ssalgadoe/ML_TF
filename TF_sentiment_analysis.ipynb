{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_index = {k:(v+3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index  = dict([(val,key) for key, val in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i,'?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                       value=word_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size,16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.6921 - acc: 0.5143 - val_loss: 0.6918 - val_acc: 0.5250\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 1s 45us/step - loss: 0.6906 - acc: 0.5307 - val_loss: 0.6901 - val_acc: 0.5344\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 1s 45us/step - loss: 0.6889 - acc: 0.5384 - val_loss: 0.6885 - val_acc: 0.5503\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 1s 44us/step - loss: 0.6869 - acc: 0.5585 - val_loss: 0.6859 - val_acc: 0.5566\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 1s 44us/step - loss: 0.6830 - acc: 0.5966 - val_loss: 0.6820 - val_acc: 0.5995\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 1s 45us/step - loss: 0.6779 - acc: 0.6447 - val_loss: 0.6764 - val_acc: 0.6429\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 1s 45us/step - loss: 0.6707 - acc: 0.6955 - val_loss: 0.6687 - val_acc: 0.6959\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 46us/step - loss: 0.6614 - acc: 0.7090 - val_loss: 0.6589 - val_acc: 0.6917\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 46us/step - loss: 0.6492 - acc: 0.7462 - val_loss: 0.6461 - val_acc: 0.7420\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 1s 54us/step - loss: 0.6326 - acc: 0.7604 - val_loss: 0.6281 - val_acc: 0.7586\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 53us/step - loss: 0.6109 - acc: 0.7778 - val_loss: 0.6073 - val_acc: 0.7724\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.5859 - acc: 0.7882 - val_loss: 0.5828 - val_acc: 0.7758\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 53us/step - loss: 0.5580 - acc: 0.7991 - val_loss: 0.5568 - val_acc: 0.7927\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 1s 65us/step - loss: 0.5283 - acc: 0.8125 - val_loss: 0.5300 - val_acc: 0.8012\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 1s 53us/step - loss: 0.4986 - acc: 0.8234 - val_loss: 0.5033 - val_acc: 0.8129\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 1s 51us/step - loss: 0.4699 - acc: 0.8369 - val_loss: 0.4780 - val_acc: 0.8212\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.4422 - acc: 0.8467 - val_loss: 0.4549 - val_acc: 0.8279\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 1s 51us/step - loss: 0.4170 - acc: 0.8558 - val_loss: 0.4338 - val_acc: 0.8356\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.3940 - acc: 0.8659 - val_loss: 0.4148 - val_acc: 0.8422\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.3740 - acc: 0.8718 - val_loss: 0.3990 - val_acc: 0.8488\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 1s 60us/step - loss: 0.3559 - acc: 0.8772 - val_loss: 0.3846 - val_acc: 0.8541\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 1s 58us/step - loss: 0.3397 - acc: 0.8830 - val_loss: 0.3725 - val_acc: 0.8566\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 1s 55us/step - loss: 0.3253 - acc: 0.8869 - val_loss: 0.3622 - val_acc: 0.8622\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 1s 56us/step - loss: 0.3124 - acc: 0.8912 - val_loss: 0.3526 - val_acc: 0.8650\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 1s 55us/step - loss: 0.3008 - acc: 0.8953 - val_loss: 0.3446 - val_acc: 0.8662\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 1s 57us/step - loss: 0.2906 - acc: 0.8970 - val_loss: 0.3377 - val_acc: 0.8690\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 1s 60us/step - loss: 0.2806 - acc: 0.9015 - val_loss: 0.3315 - val_acc: 0.8710\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 1s 60us/step - loss: 0.2716 - acc: 0.9039 - val_loss: 0.3257 - val_acc: 0.8736\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 1s 60us/step - loss: 0.2633 - acc: 0.9067 - val_loss: 0.3208 - val_acc: 0.8754\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 1s 61us/step - loss: 0.2559 - acc: 0.9084 - val_loss: 0.3165 - val_acc: 0.8764\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 1s 63us/step - loss: 0.2481 - acc: 0.9120 - val_loss: 0.3135 - val_acc: 0.8785\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 1s 62us/step - loss: 0.2416 - acc: 0.9135 - val_loss: 0.3103 - val_acc: 0.8781\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 1s 62us/step - loss: 0.2351 - acc: 0.9163 - val_loss: 0.3062 - val_acc: 0.8799\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 1s 62us/step - loss: 0.2296 - acc: 0.9185 - val_loss: 0.3035 - val_acc: 0.8814\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 1s 63us/step - loss: 0.2233 - acc: 0.9208 - val_loss: 0.3012 - val_acc: 0.8812\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 1s 64us/step - loss: 0.2177 - acc: 0.9235 - val_loss: 0.2990 - val_acc: 0.8829\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 1s 64us/step - loss: 0.2122 - acc: 0.9241 - val_loss: 0.2974 - val_acc: 0.8828\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 1s 65us/step - loss: 0.2072 - acc: 0.9272 - val_loss: 0.2954 - val_acc: 0.8833\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 1s 77us/step - loss: 0.2029 - acc: 0.9282 - val_loss: 0.2937 - val_acc: 0.8846\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 1s 77us/step - loss: 0.1975 - acc: 0.9313 - val_loss: 0.2922 - val_acc: 0.8859\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=40,batch_size=512,\n",
    "                   validation_data=(x_val,y_val),\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 19us/step\n",
      "[0.306352166261673, 0.87376]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data,test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['acc', 'val_loss', 'loss', 'val_acc'])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history_dict['acc']\n",
    "val_loss = history_dict['val_loss']\n",
    "loss = history_dict['loss']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validataion Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validataion Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
